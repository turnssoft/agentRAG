# ─── Chat LLM settings ─────────────────────────────────────────────────────
LLM_HOST=http://localhost:12434
LLM_ENGINE=llama.cpp
OLLAMA_MODEL=ai/llama3.2:latest

# ─── System & Prompt ────────────────────────────────────────────────────────
ROLE_SYSTEM_CONTENT=You are a helpful assistant.
# ─── Prompt template with literal line breaks ───────────────────────────────
# PROMPT_TEMPLATE="You are an expert in answering questions about a pizza restaurant.\n\nHere are some relevant reviews: {reviews}\n\nHere is the question to answer: {question}"
PROMPT_TEMPLATE="You are an expert analyst for a pizza restaurant. You have access to a variety of documents including customer reviews, sales transactions, and other records.\n\nBased on the following context:\n{reviews}\n\nPlease answer the following question clearly and accurately:\n{question}\n\nIf the question is specific (e.g. 'how many...'), give a direct, concise answer. If the question is open-ended (e.g. 'what do people think...'), summarize relevant insights."

# ─── Embedding service ─────────────────────────────────────────────────────
EMBEDDING_HOST=http://localhost:12434
EMBEDDING_ENGINE=llama.cpp
EMBEDDING_MODEL=ai/mxbai-embed-large

# ─── Vector store rebuild toggle ───────────────────────────────────────────
REBUILD_VECTOR=false

# ─── ChromaDB backend engine ───────────────────────────────────────────────
DB_LOCATION="./chrome_langchain_db"
COLLECTION_NAME="PizzaBoys"

# ─── Data folder ────────────────────────────────────────────────────────────
DATA_FOLDER="./data"

# ─── Splitter settings ──────────────────────────────────────────────────────
CHUNK_SIZE=500
CHUNK_OVERLAP=100

# ─── Top K for retrieval ───────────────────────────────────────────────────
RETRIEVAL_TOP_K=10
